import random
random.seed(42)  # Define a semente aleatÃ³ria para garantir reprodutibilidade dos resultados

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg  # Biblioteca para exibir imagens

# ğŸ“Œ Carregar os dados do conjunto de dados Iris
data = pd.read_csv('iris.csv', header=0)  # LÃª o arquivo CSV contendo os dados da Ã­ris
data = data.dropna(axis='rows')  # Remove valores ausentes (NaN) para evitar erros

# ğŸ“Œ Armazena os nomes das classes (espÃ©cies de flores)
classes = np.array(pd.unique(data[data.columns[-1]]), dtype=str)  # ObtÃ©m os nomes das classes Ãºnicas
print("NÃºmero de linhas e colunas na matriz de atributos:", data.shape)  # Exibe a dimensÃ£o do dataset

# ğŸ“Œ Lista os nomes das colunas (atributos)
attributes = list(data.columns)
print(data.head(10))  # Exibe as primeiras 10 linhas do dataset para ver os dados

# ğŸ“Œ Converter os dados para um array NumPy para facilitar o processamento
data = data.to_numpy()
nrow, ncol = data.shape  # ObtÃ©m o nÃºmero de linhas e colunas
y = data[:, -1]  # Ãšltima coluna representa as classes das flores (rÃ³tulos)
x = data[:, 0:ncol-1]  # Demais colunas sÃ£o os atributos

# ğŸ“Œ Dividir os dados em conjuntos de treinamento e teste
from sklearn.model_selection import train_test_split
p = 0.7  # Define que 70% dos dados serÃ£o usados para treinamento e 30% sÃ£o para teste
x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=p, random_state=42)

# ğŸ“Œ DefiniÃ§Ã£o de uma funÃ§Ã£o para calcular a densidade de probabilidade conjunta usando distribuiÃ§Ã£o Gaussiana
def likelihood(y, Z):
    def gaussian(x, mu, sig):
        """FunÃ§Ã£o da distribuiÃ§Ã£o Gaussiana (Normal)"""
        return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
    
    prob = 1
    for j in range(Z.shape[1]):  # Percorre todas as colunas (atributos)
        m = np.mean(Z[:, j])  # Calcula a mÃ©dia dos valores do atributo
        s = np.std(Z[:, j])  # Calcula o desvio padrÃ£o do atributo
        if s == 0:  # Evita divisÃ£o por zero
            s = 1e-6
        prob *= gaussian(y[j], m, s)  # Multiplica as probabilidades individuais
    return prob

# ğŸ“Œ Criar um DataFrame para armazenar probabilidades de cada classe
P = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns=classes)

# ğŸ“Œ CÃ¡lculo da probabilidade de cada classe para cada amostra do conjunto de teste
for i in range(len(classes)):  # Para cada classe no conjunto de dados
    elements = np.where(y_train == classes[i])[0]  # ObtÃ©m os Ã­ndices das amostras da classe atual
    Z = x_train[elements, :]  # Filtra os dados da classe correspondente

    for j in range(x_test.shape[0]):  # Para cada amostra do conjunto de teste
        x_sample = x_test[j, :]
        pj = likelihood(x_sample, Z)  # Calcula a probabilidade da amostra pertencer Ã  classe
        P.loc[j, classes[i]] = pj * len(elements) / x_train.shape[0]  # Multiplica pela probabilidade a priori

# ğŸ“Œ Exibir as probabilidades calculadas
print(P.head(10))

# ğŸ“Œ Exibir uma imagem ilustrativa
img = mpimg.imread('iris_type.jpg')  
plt.figure(figsize=(10, 5))
plt.axis('off')
plt.imshow(img)
plt.show()

# ğŸ“Œ Calcula a acurÃ¡cia do classificador manual
from sklearn.metrics import accuracy_score

y_pred = []
for i in range(P.shape[0]):  # Para cada amostra no conjunto de teste
    c = np.argmax(P.iloc[i].values)  # ObtÃ©m o Ã­ndice da classe com maior probabilidade
    y_pred.append(P.columns[c])  # Armazena o nome da classe prevista

y_pred = np.array(y_pred)  # Converte a lista para array NumPy

# ğŸ“Œ Calcular e exibir a acurÃ¡cia do modelo
score = accuracy_score(y_pred, y_test)
print('Accuracy:', score)

# ğŸ“Œ Exibir a matriz de confusÃ£o para avaliar os erros do modelo
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(np.array(y_test, dtype=str), np.array(y_pred, dtype=str))
print("Confusion Matrix:")
print(cm)

# ğŸ“Œ Testes independentes usando bibliotecas do Scikit-Learn
# ClassificaÃ§Ã£o usando Naive Bayes Gaussiano (assume distribuiÃ§Ã£o normal dos atributos)
from sklearn.naive_bayes import GaussianNB

model = GaussianNB()
model.fit(x_train, y_train)  # Treina o modelo
y_pred = model.predict(x_test)  # Faz previsÃµes no conjunto de teste
score = accuracy_score(y_pred, y_test)  # Calcula a acurÃ¡cia
print('Accuracy utilizando GaussianNB:', score)

# ğŸ“Œ Teste usando Bernoulli Naive Bayes (assume atributos binÃ¡rios)
from sklearn.naive_bayes import BernoulliNB

model = BernoulliNB()
model.fit(x_train, y_train)  # Treina o modelo
y_pred = model.predict(x_test)  # Faz previsÃµes no conjunto de teste
score = accuracy_score(y_pred, y_test)  # Calcula a acurÃ¡cia
print('Accuracy utilizando BernoulliNB:', score)

# ğŸ“Œ Exibir previsÃµes comparando valores reais e previstos
df = pd.DataFrame({'Real Values': y_test, 'Predicted Values': y_pred})
print(df.head(10))  
